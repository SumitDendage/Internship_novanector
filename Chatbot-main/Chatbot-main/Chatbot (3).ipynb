{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Afv76nxlaJpS"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "import string\n",
        "import random"
      ],
      "metadata": {
        "id": "IIz_PAfEav3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading the Corpus of Text"
      ],
      "metadata": {
        "id": "a54UROr4lynv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = open('/content/data_doc.txt', 'r',  errors='ignore')\n",
        "raw_doc = f.read()"
      ],
      "metadata": {
        "id": "2w7Ozisna7pE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_doc = raw_doc.lower()\n",
        "nltk.download('punkt_tab')  # Download the punkt_tab resource\n",
        "nltk.download('worknet')\n",
        "nltk.download('omw-1.4')\n",
        "sentence_tokens=nltk.sent_tokenize(raw_doc)\n",
        "word_tokens=nltk.word_tokenize(raw_doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oO8FfeWubnR9",
        "outputId": "49977058-38a9-4e89-8482-f18a2bb23dba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Error loading worknet: Package 'worknet' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " raw_doc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "rGRGgs6lcY2p",
        "outputId": "3d496422-a38c-4b58-8506-5bd225f153e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'For the bot-creation software, see ChatBot. For bots on Internet Relay Chat, see IRC bot.\\n\\nA virtual assistant chatbot\\n\\nThe 1966 ELIZA chatbot\\nPart of a series on\\nMachine learning\\nand data mining\\nParadigms\\nProblems\\nSupervised learning\\n(classification • regression)\\nClustering\\nDimensionality reduction\\nStructured prediction\\nAnomaly detection\\nArtificial neural network\\nAutoencoderDeep learningFeed forward neural network Recurrent neural network LSTMGRUESNreservoir computing Boltzmann machine RestrictedGAN Diffusion mode lSOM Convolutional neural network U-NetLeNetAlex NetDeep Dream Neural radiance field Transformer VisionMambaSpiking neural network Mem transistor Electrochemical RAM (ECRAM)\\nReinforcement learning\\nLearning with humans\\nModel diagnostics\\nMathematical foundations\\nJournals and conferences\\nRelated articles\\nvte\\nA chatbot (originally chatterbot)[1] is a software application or web interface designed to have textual or spoken conversations.[2][3][4] Modern chatbots are typically online and use generative artificial intelligence systems that are capable of maintaining a conversation with a user in natural language and simulating the way a human would behave as a conversational partner. Such chatbots often use deep learning and natural language processing, but simpler chatbots have existed for decades.\\n\\nAlthough chatbots have existed since the late 1960s, the field gained widespread attention in the early 2020s due to the popularity of OpenAI\\'s ChatGPT,[5][6] followed by alternatives such as Microsoft\\'s Copilot and Google\\'s Gemini.[7] Such examples reflect the recent practice of basing such products upon broad foundational large language models, such as GPT-4 or the Gemini language model, that get fine-tuned so as to target specific tasks or applications (i.e., simulating human conversation, in the case of chatbots). Chatbots can also be designed or customized to further target even more specific situations and/or particular subject-matter domains.[8]\\n\\nA major area where chatbots have long been used is in customer service and support, with various sorts of virtual assistants.[9] Companies spanning a wide range of industries have begun using the latest generative artificial intelligence technologies to power more advanced developments in such areas.[8]\\n\\nHistory\\nTuring test\\nIn 1950, Alan Turing\\'s famous article \"Computing Machinery and Intelligence\" was published,[10] which proposed what is now called the Turing test as a criterion of intelligence. This criterion depends on the ability of a computer program to impersonate a human in a real-time written conversation with a human judge to the extent that the judge is unable to distinguish reliably—on the basis of the conversational content alone—between the program and a real human.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_tokens=nltk.sent_tokenize(raw_doc)\n",
        "word_tokens=nltk.word_tokenize(raw_doc)"
      ],
      "metadata": {
        "id": "xuct-JrCeb14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**After Tokenization**"
      ],
      "metadata": {
        "id": "LL8YVxxvgtz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_tokens[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "5-dDwziRft81",
        "outputId": "960f94a9-f07d-4e9a-b79f-e1aa7af0f734"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A virtual assistant chatbot\\n\\nThe 1966 ELIZA chatbot\\nPart of a series on\\nMachine learning\\nand data mining\\nParadigms\\nProblems\\nSupervised learning\\n(classification • regression)\\nClustering\\nDimensionality reduction\\nStructured prediction\\nAnomaly detection\\nArtificial neural network\\nAutoencoderDeep learningFeed forward neural network Recurrent neural network LSTMGRUESNreservoir computing Boltzmann machine RestrictedGAN Diffusion mode lSOM Convolutional neural network U-NetLeNetAlex NetDeep Dream Neural radiance field Transformer VisionMambaSpiking neural network Mem transistor Electrochemical RAM (ECRAM)\\nReinforcement learning\\nLearning with humans\\nModel diagnostics\\nMathematical foundations\\nJournals and conferences\\nRelated articles\\nvte\\nA chatbot (originally chatterbot)[1] is a software application or web interface designed to have textual or spoken conversations.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokens[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKSTDH0dgggp",
        "outputId": "b797c62c-cfcb-4138-db1f-2192e658bec3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['For', 'the']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Performing Text-PreProcessing Steps**"
      ],
      "metadata": {
        "id": "GTt8yBDng8T9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmer=nltk.stem.WordNetLemmatizer()\n",
        "def LemTokens(tokens):\n",
        "  return [lemmer.lemmatize(token) for token in tokens]\n",
        "  remove_punct_dict=dict((ord(punct),None) for punct in string.punctuation)\n",
        "  def LemNormalize(text):\n",
        "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
      ],
      "metadata": {
        "id": "Loefz8lIgpDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Greeting Functions"
      ],
      "metadata": {
        "id": "td-pE_dWhYzh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "greet_inputs=(\"hello\",\"hi\",\"whassup\",\"how are you?\")\n",
        "greet_response=(\"hi\",\"hey\",\"nods\",\"hi there\")\n",
        "def greet(sentence):\n",
        "  for word in sentence.split():\n",
        "    if word.lower() in greet_inputs:\n",
        "      return random.choice(greet_response)"
      ],
      "metadata": {
        "id": "m1EnLWWAhWix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Response Generation By the bot"
      ],
      "metadata": {
        "id": "VUkTdaklhu78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def response(user_response):\n",
        "  robo1_response=''\n",
        "  TfidfVec=TfidfVectorizer(tokenizer=LemNormalize,stop_words='english')\n",
        "  tfidf=TfidfVec.fit_transform(sentence_tokens)\n",
        "  valis = cosine_similarity(tfidf[-1],tfidf)\n",
        "  idx = valis.argsort()[0][-2]\n",
        "  flat = valis.flatten()\n",
        "  flat.sort()\n",
        "  req_tfidf = flat[-2]\n",
        "  if(req_tfidf==0):\n",
        "    robo1_response=robo1_response+\"I am sorry! I don't understand you\"\n",
        "    return robo1_response\n",
        "  else:\n",
        "    robo1_response = robo1_response+sentence_tokens[idx]\n",
        "    return robo1_response"
      ],
      "metadata": {
        "id": "Jc0ssfhQhpOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining The ChatFlow"
      ],
      "metadata": {
        "id": "cbv-DqaWirZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flag = True\n",
        "print('Hello! I am Learning Bot. Start typing your text after greeting to talk to me. For ending convo type bye!')\n",
        "\n",
        "while flag:\n",
        "    user_response = input()\n",
        "    user_response = user_response.lower()\n",
        "\n",
        "    if user_response != 'bye':\n",
        "        if user_response == 'thanks' or user_response == 'thank you':\n",
        "            flag = False\n",
        "            print('You are welcome..')\n",
        "        else:\n",
        "            if greet(user_response) is not None:\n",
        "                print('Learning Bot: ' + greet(user_response))\n",
        "            else:\n",
        "                sentence_tokens.append(user_response)\n",
        "                word_tokens = word_tokens + nltk.word_tokenize(user_response)\n",
        "                final_words = list(set(word_tokens))\n",
        "                print('Learning Bot:', end='')\n",
        "                print(response(user_response))\n",
        "                sentence_tokens.remove(user_response)\n",
        "    else:\n",
        "        flag = False\n",
        "        print('Bot: Goodbye')\n",
        "\n",
        "    if user_response != 'bye':\n",
        "        if user_response == 'thanks' or user_response == 'thank you':\n",
        "            flag = False\n",
        "            print('You are welcome..')\n",
        "        else:\n",
        "            if greet(user_response) is not None:\n",
        "                print('Learning Bot: ' + greet(user_response))\n",
        "            else:\n",
        "                sentence_tokens.append(user_response)\n",
        "                word_tokens = word_tokens + nltk.word_tokenize(user_response)\n",
        "                final_words = list(set(word_tokens))\n",
        "                print('Learning Bot:', end='')\n",
        "                print(response(user_response))\n",
        "                sentence_tokens.remove(user_response)\n",
        "    else:\n",
        "        flag = False\n",
        "        print('Bot: Goodbye')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8l7i71FRiXU5",
        "outputId": "2531eb15-0f0e-4af2-f306-0d514d7ed1ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! I am Learning Bot. Start typing your text after greeting to talk to me. For ending convo type bye!\n",
            "Hello\n",
            "Learning Bot: Hi there!\n",
            "Learning Bot: Hello!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4bh18wbqjIDd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}